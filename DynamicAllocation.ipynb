{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObXwfowWSUvUNHXJGHbxKG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evanss2025/Exploring-Slime-Mold-Inspired-Strategies-for-Improved-Domain-Adaptation-for-Visual-Recognition-in-ML/blob/main/DynamicAllocation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIIwJ7xeAnM1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploring Slime Mold-Inspired Strategies for Improved Domain Adaptation for Visual Recognition in ML**\n",
        "\n",
        "This code is a part of Sophia Evans's research project. The following creates a domain shift situation in which the SVHN dataset is used to train and validate a classification model, but then the model predicts on the MNIST dataset. This creates domain shift as although both are number datasets, the SVHN dataset introduces new lighting and features that the MNIST dataset does not have, limiting it's efficiency."
      ],
      "metadata": {
        "id": "sVNxihrT9hjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "RLbBYp6S9843"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPId0FOwI8Y_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the SVHN dataset. The dataset is downloaded from tensorflow's datasets and the appropriate feautres are extracted from it."
      ],
      "metadata": {
        "id": "hGFX4_b9-BDf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANkVdPUAI-LZ"
      },
      "outputs": [],
      "source": [
        "# Load SVHN dataset\n",
        "svhn_builder = tfds.builder('svhn_cropped')\n",
        "svhn_builder.download_and_prepare()\n",
        "svhn_dataset = tfds.load('svhn_cropped', split='train', as_supervised=True)\n",
        "svhn_dataset = tfds.as_numpy(svhn_dataset)\n",
        "\n",
        "# Extract features and labels from SVHN dataset\n",
        "x_svhn = np.array([tf.image.rgb_to_grayscale(sample[0]).numpy().astype('float32') / 255 for sample in svhn_dataset])\n",
        "y_svhn = np.array([sample[1] for sample in svhn_dataset])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the SVHN dataset"
      ],
      "metadata": {
        "id": "prmT6vuS-KtS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhpTBRaJlPab"
      },
      "outputs": [],
      "source": [
        "# Split data into train and test sets for the source domain (SVHN)\n",
        "source_train_data, source_test_data, y_svhn_train, y_svhn_test = train_test_split(\n",
        "    x_svhn, y_svhn, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "# Ensure target labels have the same shape as source labels\n",
        "y_svhn_train = tf.keras.utils.to_categorical(y_svhn_train, num_classes=10)\n",
        "y_svhn_test = tf.keras.utils.to_categorical(y_svhn_test, num_classes=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the MNIST dataset from Keras, and then preprocessing the dataset."
      ],
      "metadata": {
        "id": "TTcrFs6u-Vxx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bz2AfG_kJDjM"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_mnist, y_mnist), (_, _) = mnist.load_data()\n",
        "\n",
        "# Resize MNIST images to 32x32 pixels\n",
        "x_mnist_resized = tf.image.resize(x_mnist[..., tf.newaxis], (32, 32))\n",
        "x_mnist_resized = tf.squeeze(x_mnist_resized)\n",
        "\n",
        "# Preprocess MNIST data\n",
        "x_mnist_resized = x_mnist_resized.numpy()  # Convert to NumPy array\n",
        "x_mnist_resized = x_mnist_resized.reshape((x_mnist_resized.shape[0], 32, 32, 1)).astype('float32') / 255\n",
        "y_mnist = tf.keras.utils.to_categorical(y_mnist, num_classes=10)\n",
        "\n",
        "# Split data into train and test sets for the target domain (MNIST)\n",
        "target_train_data, target_test_data, target_train_labels, target_test_labels = train_test_split(\n",
        "    x_mnist_resized, y_mnist, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing an example from each dataset ensuring that they are both the same size and are compatible."
      ],
      "metadata": {
        "id": "dUycSZe_-dfT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpY8eAzEJFJs"
      },
      "outputs": [],
      "source": [
        "# Visualize an example image from each dataset\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "# SVHN\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(source_train_data[0].reshape(32, 32), cmap='gray')\n",
        "plt.title('SVHN Sample')\n",
        "\n",
        "# MNIST\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(target_train_data[0], cmap='gray')\n",
        "plt.title('MNIST Sample')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dynamic resource allocation function\n",
        "def dynamic_allocation(model, source_data, target_data):\n",
        "    source_shape = source_data.shape[1:]\n",
        "    target_shape = target_data.shape[1:]\n",
        "\n",
        "    # Gradual adaptation based on the number of channels\n",
        "    if source_shape[-1] != target_shape[-1]:\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Gradual adaptation based on the mean of pixel values\n",
        "    source_mean = np.mean(source_data)\n",
        "    target_mean = np.mean(target_data)\n",
        "    if np.abs(source_mean - target_mean) > 0.05:\n",
        "        # Ensure input shape is correct before adding Conv2D layer\n",
        "        if len(model.layers[-1].output_shape) == 4:\n",
        "            model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "            model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Gradual adaptation based on the variance of pixel values\n",
        "    source_var = np.var(source_data)\n",
        "    target_var = np.var(target_data)\n",
        "    if np.abs(source_var - target_var) > 0.05:\n",
        "        # Ensure input shape is correct before adding Conv2D layer\n",
        "        if len(model.layers[-1].output_shape) == 4:\n",
        "            model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
        "            model.add(layers.MaxPooling2D((2, 2)))"
      ],
      "metadata": {
        "id": "njPgrzihA8xS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the model architecture, applying the dynamic resource allocation strategy, compiling the model, and then train the model on the SVHN dataset\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KyqvxPGM-r7c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wixJVwU2HQRl"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten layer\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Dense layers\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Apply dynamic resource allocation\n",
        "dynamic_allocation(model, source_train_data, target_train_data)\n",
        "\n",
        "# Display the updated model summary\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train on the source domain (SVHN)\n",
        "model.fit(source_train_data, y_svhn_train, epochs=10, validation_data=(source_test_data, y_svhn_test), batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SVHN trained model predicts on the MNIST dataset and outputs the accuracy and F1-score"
      ],
      "metadata": {
        "id": "hx9uWZIp_EQ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db5-D7-zlV2O"
      },
      "outputs": [],
      "source": [
        "# Evaluate on the target domain\n",
        "target_predictions = model.predict(target_test_data)\n",
        "target_accuracy = accuracy_score(np.argmax(target_test_labels, axis=1), np.argmax(target_predictions, axis=1))\n",
        "target_f1_score = f1_score(np.argmax(target_test_labels, axis=1), np.argmax(target_predictions, axis=1), average='weighted')\n",
        "\n",
        "print(f\"Target Domain Accuracy: {target_accuracy}\")\n",
        "print(f\"Target Domain F1 Score: {target_f1_score}\")"
      ]
    }
  ]
}